---

title: Models Bert2GPT2

keywords: fastai
sidebar: home_sidebar


---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/03c_models.bert2gpt2.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<p style="color: red;">
The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>
We recommend you <a href="https://www.tensorflow.org/guide/migrate" target="_blank">upgrade</a> now 
or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:
<a href="https://colab.research.google.com/notebooks/tensorflow_version.ipynb" target="_blank">more info</a>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<p style="color: red;">
The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>
We recommend you <a href="https://www.tensorflow.org/guide/migrate" target="_blank">upgrade</a> now 
or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:
<a href="https://colab.research.google.com/notebooks/tensorflow_version.ipynb" target="_blank">more info</a>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">enc_model_name</span> <span class="o">=</span> <span class="s1">&#39;hfl/chinese-bert-wwm-ext&#39;</span>
<span class="n">dec_model_name</span> <span class="o">=</span> <span class="s1">&#39;distilgpt2&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">enc_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">enc_model_name</span><span class="p">)</span>
<span class="n">dec_tokenizer</span> <span class="o">=</span> <span class="n">GPT2DecoderTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">dec_model_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Helper-functions">Helper functions<a class="anchor-link" href="#Helper-functions">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gen_attention_mask" class="doc_header"><code>gen_attention_mask</code><a href="https://github.com/cwza/nmt_small/tree/master/nmt_small/models/bert2gpt2.py#L16" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>gen_attention_mask</code>(<strong><code>inp_ids</code></strong>, <strong><code>pad_id</code></strong>)</p>
</blockquote>
<p>Returns Tensor where 0 are positions that contain pad_id, others 1.
input_ids: (bs, seq_len) returns: (bs, seq_len)</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> 
                          <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">attention_mask</span> <span class="o">=</span> <span class="n">gen_attention_mask</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                                      <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="BertEncoder">BertEncoder<a class="anchor-link" href="#BertEncoder">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BertEncoder" class="doc_header"><code>class</code> <code>BertEncoder</code><a href="https://github.com/cwza/nmt_small/tree/master/nmt_small/models/bert2gpt2.py#L25" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BertEncoder</code>(<strong><code>model_name</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">enc_seq_len</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">src_strs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;測試&#39;</span><span class="p">,</span> <span class="s1">&#39;你好嗎&#39;</span><span class="p">,</span> <span class="s1">&#39;早安&#39;</span><span class="p">]</span>
<span class="n">src_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">enc_tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">src_str</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">enc_seq_len</span><span class="p">,</span> <span class="n">pad_to_max_length</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">src_str</span> <span class="ow">in</span> <span class="n">src_strs</span><span class="p">])</span>
<span class="n">src_attention_mask</span> <span class="o">=</span> <span class="n">gen_attention_mask</span><span class="p">(</span><span class="n">src_input_ids</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">)</span>
<span class="n">src_input_ids</span><span class="p">,</span> <span class="n">src_attention_mask</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([[ 101, 3947, 6275,  102,    0,    0,    0,    0,    0,    0],
         [ 101,  872, 1962, 1621,  102,    0,    0,    0,    0,    0],
         [ 101, 3193, 2128,  102,    0,    0,    0,    0,    0,    0]]),
 tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],
         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">encoder</span> <span class="o">=</span> <span class="n">BertEncoder</span><span class="p">(</span><span class="n">enc_model_name</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">encoder</span><span class="p">(</span><span class="n">src_input_ids</span><span class="p">,</span> <span class="n">src_attention_mask</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">enc_seq_len</span><span class="p">,</span> <span class="n">encoder</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="CrossAttention">CrossAttention<a class="anchor-link" href="#CrossAttention">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BatchFirstMultiheadAttention" class="doc_header"><code>class</code> <code>BatchFirstMultiheadAttention</code><a href="https://github.com/cwza/nmt_small/tree/master/nmt_small/models/bert2gpt2.py#L40" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BatchFirstMultiheadAttention</code>(<strong><code>embed_dim</code></strong>, <strong><code>num_heads</code></strong>, <strong><code>dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>bias</code></strong>=<em><code>True</code></em>, <strong><code>add_bias_kv</code></strong>=<em><code>False</code></em>, <strong><code>add_zero_attn</code></strong>=<em><code>False</code></em>, <strong><code>kdim</code></strong>=<em><code>None</code></em>, <strong><code>vdim</code></strong>=<em><code>None</code></em>) :: <code>MultiheadAttention</code></p>
</blockquote>
<p>Pytorch wants your query, key, value be (seq_len, b, embed_dim) and return (seq_len, b, embed_dim)
But I like batch-first thing. input: (b, seq_len, embed_dim) output: (b, seq_len, embed_dim)</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">multi_attn</span> <span class="o">=</span> <span class="n">BatchFirstMultiheadAttention</span><span class="p">(</span><span class="n">embed_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">768</span><span class="p">))</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">768</span><span class="p">))</span>
<span class="n">value</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">768</span><span class="p">))</span>
<span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_weight</span> <span class="o">=</span> <span class="n">multi_attn</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">attn_output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">768</span><span class="p">))</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">attn_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="CrossAttention" class="doc_header"><code>class</code> <code>CrossAttention</code><a href="https://github.com/cwza/nmt_small/tree/master/nmt_small/models/bert2gpt2.py#L60" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>CrossAttention</code>(<strong><code>embed_dim</code></strong>, <strong><code>num_heads</code></strong>=<em><code>1</code></em>, <strong><code>drop_p</code></strong>=<em><code>0</code></em>, <strong><code>num_layers</code></strong>=<em><code>1</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tgt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">768</span><span class="p">))</span>
<span class="n">src</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">768</span><span class="p">))</span>
<span class="n">src_key_padding_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>
<span class="n">cross_attn</span> <span class="o">=</span> <span class="n">CrossAttention</span><span class="p">(</span><span class="n">embed_dim</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">cross_attn_out</span><span class="p">,</span> <span class="n">cross_attn_weight</span> <span class="o">=</span> <span class="n">cross_attn</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_key_padding_mask</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">cross_attn_out</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">768</span><span class="p">))</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">cross_attn_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="GPT2Decoder">GPT2Decoder<a class="anchor-link" href="#GPT2Decoder">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gpt2</span> <span class="o">=</span> <span class="n">AutoModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">dec_model_name</span><span class="p">)</span>
<span class="n">old_wte</span> <span class="o">=</span> <span class="n">gpt2</span><span class="o">.</span><span class="n">wte</span>
<span class="n">new_wte</span> <span class="o">=</span> <span class="n">_adujsted_gpt2wte</span><span class="p">(</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">test_eq</span><span class="p">(</span><span class="n">old_wte</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">new_wte</span><span class="o">.</span><span class="n">weight</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">new_wte</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">old_wte</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">)))</span> <span class="c1"># zero</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">new_wte</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">old_wte</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="c1"># mean of old</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="GPT2Decoder" class="doc_header"><code>class</code> <code>GPT2Decoder</code><a href="https://github.com/cwza/nmt_small/tree/master/nmt_small/models/bert2gpt2.py#L100" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>GPT2Decoder</code>(<strong><code>model_name</code></strong>, <strong><code>pad_id</code></strong>, <strong><code>vocab_size</code></strong>, <strong><code>num_heads</code></strong>=<em><code>1</code></em>, <strong><code>drop_p</code></strong>=<em><code>0</code></em>, <strong><code>num_layers</code></strong>=<em><code>1</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">GPT2Decoder</span><span class="p">(</span>
    <span class="n">dec_model_name</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">dec_tokenizer</span><span class="p">),</span>
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">drop_p</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># test embedding</span>
<span class="n">test_eq</span><span class="p">((</span><span class="n">decoder</span><span class="o">.</span><span class="n">gpt2</span><span class="o">.</span><span class="n">wte</span><span class="o">.</span><span class="n">num_embeddings</span><span class="p">,</span> <span class="n">decoder</span><span class="o">.</span><span class="n">gpt2</span><span class="o">.</span><span class="n">wte</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">),</span> <span class="p">(</span><span class="n">gpt2</span><span class="o">.</span><span class="n">wte</span><span class="o">.</span><span class="n">num_embeddings</span><span class="o">+</span><span class="mi">2</span><span class="p">,</span> <span class="n">gpt2</span><span class="o">.</span><span class="n">wte</span><span class="o">.</span><span class="n">embedding_dim</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># test forward shape</span>
<span class="n">tgt_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50259</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">))</span>
<span class="n">memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">768</span><span class="p">))</span>
<span class="n">memory_key_padding_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span><span class="o">.</span><span class="n">bool</span><span class="p">()</span>

<span class="n">output</span><span class="p">,</span> <span class="n">attn_weight</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">tgt_input_ids</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_key_padding_mask</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dec_tokenizer</span><span class="p">)))</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">attn_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Bert2Gpt2">Bert2Gpt2<a class="anchor-link" href="#Bert2Gpt2">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Bert2GPT2" class="doc_header"><code>class</code> <code>Bert2GPT2</code><a href="https://github.com/cwza/nmt_small/tree/master/nmt_small/models/bert2gpt2.py#L136" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Bert2GPT2</code>(<strong><code>encoder</code></strong>:<a href="/nmt_small/03c_models.bert2gpt2#BertEncoder"><code>BertEncoder</code></a>, <strong><code>decoder</code></strong>:<a href="/nmt_small/03c_models.bert2gpt2#GPT2Decoder"><code>GPT2Decoder</code></a>, <strong><code>enc_pad_id</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bert2gpt2</span> <span class="o">=</span> <span class="n">Bert2GPT2</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">)</span>
<span class="n">src_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_tokenizer</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span> <span class="c1"># (bs, enc_seq_len)</span>
<span class="n">tgt_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dec_tokenizer</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">))</span> <span class="c1"># (bs, dec_seq_len)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">bert2gpt2</span><span class="p">(</span><span class="n">src_input_ids</span><span class="p">,</span> <span class="n">tgt_input_ids</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dec_tokenizer</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="GeneratedBert2GPT2">GeneratedBert2GPT2<a class="anchor-link" href="#GeneratedBert2GPT2">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="GeneratedBert2GPT2" class="doc_header"><code>class</code> <code>GeneratedBert2GPT2</code><a href="https://github.com/cwza/nmt_small/tree/master/nmt_small/models/bert2gpt2.py#L159" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>GeneratedBert2GPT2</code>(<strong><code>seq2seq</code></strong>:<a href="/nmt_small/03c_models.bert2gpt2#Bert2GPT2"><code>Bert2GPT2</code></a>, <strong><code>enc_tokenizer</code></strong>:<code>PreTrainedTokenizer</code>, <strong><code>dec_tokenizer</code></strong>:<code>PreTrainedTokenizer</code>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="generate_from_ids">generate_from_ids<a class="anchor-link" href="#generate_from_ids">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="generate_from_ids" class="doc_header"><code>generate_from_ids</code><a href="https://github.com/cwza/nmt_small/tree/master/nmt_small/models/bert2gpt2.py#L172" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>generate_from_ids</code>(<strong><code>src_input_ids</code></strong>, <strong><code>generate_args</code></strong>:<code>GenerateArgs</code>)</p>
</blockquote>
<p>src_input_ids: (bs, enc_seq_len), returns: (bs, max_length)</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">generated_bert2gpt2</span> <span class="o">=</span> <span class="n">GeneratedBert2GPT2</span><span class="p">(</span><span class="n">bert2gpt2</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="p">)</span>

<span class="n">generate_args</span> <span class="o">=</span> <span class="n">GenerateArgs</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">src_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_tokenizer</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span> <span class="c1"># (bs, enc_seq_len)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">generated_bert2gpt2</span><span class="o">.</span><span class="n">generate_from_ids</span><span class="p">(</span><span class="n">src_input_ids</span><span class="p">,</span> <span class="n">generate_args</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>
 

