---

title: Models Patch

keywords: fastai
sidebar: home_sidebar


---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/03a_models.patch.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    {% raw %}
        
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<p style="color: red;">
The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>
We recommend you <a href="https://www.tensorflow.org/guide/migrate" target="_blank">upgrade</a> now 
or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:
<a href="https://colab.research.google.com/notebooks/tensorflow_version.ipynb" target="_blank">more info</a>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">enc_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;hfl/chinese-bert-wwm-ext&#39;</span><span class="p">)</span>
<span class="n">dec_tokenizer</span> <span class="o">=</span> <span class="n">GPT2DecoderTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;distilgpt2&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="GeneratedSeq2Seq.generate_from_strs()">GeneratedSeq2Seq.generate_from_strs()<a class="anchor-link" href="#GeneratedSeq2Seq.generate_from_strs()">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="generate_from_strs" class="doc_header"><code>generate_from_strs</code><a href="https://github.com/cwza/nmt_try/tree/master/nmt_try/models/patch.py#L19" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>generate_from_strs</code>(<strong><code>src_strs</code></strong>, <strong><code>generate_args</code></strong>:<code>GenerateArgs</code>, <strong><code>device</code></strong>)</p>
</blockquote>
<p>self.seq2seq.eval, self.enc_tokenizer.encode, self.dec_tokenizer.decode, self.generate_from_ids</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Test for GeneratedGRU2GRU</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">GRUEncoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">enc_tokenizer</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">GRUDecoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dec_tokenizer</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">gru2gru</span> <span class="o">=</span> <span class="n">GRU2GRU</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">generated_gru2gru</span> <span class="o">=</span> <span class="n">GeneratedGRU2GRU</span><span class="p">(</span><span class="n">gru2gru</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="p">)</span>

<span class="n">generate_args</span> <span class="o">=</span> <span class="n">GenerateArgs</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">src_strs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;天氣不錯&#39;</span><span class="p">,</span> <span class="s1">&#39;你好&#39;</span><span class="p">]</span>
<span class="n">pred_strs</span> <span class="o">=</span> <span class="n">generated_gru2gru</span><span class="o">.</span><span class="n">generate_from_strs</span><span class="p">(</span><span class="n">src_strs</span><span class="p">,</span> <span class="n">generate_args</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">pred_strs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).
To remove this error, you can add a new pad token and then resize model embedding:
	tokenizer.pad_token = &#39;&lt;PAD&gt;&#39;
	model.resize_token_embeddings(len(tokenizer))
Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).
To remove this error, you can add a new pad token and then resize model embedding:
	tokenizer.pad_token = &#39;&lt;PAD&gt;&#39;
	model.resize_token_embeddings(len(tokenizer))
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;Bo Stronghold Jian LW morality Tubico Welch&#39;,
 &#39; pondevaluate Retro HR Assass Productionsawa gate&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Test for GeneratedTran2Tran</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">TranEncoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">enc_tokenizer</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">TranDecoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dec_tokenizer</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">)</span>
<span class="n">tran2tran</span> <span class="o">=</span> <span class="n">Tran2Tran</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">)</span>
<span class="n">generated_tran2tran</span> <span class="o">=</span> <span class="n">GeneratedTran2Tran</span><span class="p">(</span><span class="n">tran2tran</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="p">)</span>

<span class="n">generate_args</span> <span class="o">=</span> <span class="n">GenerateArgs</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">src_strs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;天氣不錯&#39;</span><span class="p">,</span> <span class="s1">&#39;你好&#39;</span><span class="p">]</span>
<span class="n">pred_strs</span> <span class="o">=</span> <span class="n">generated_tran2tran</span><span class="o">.</span><span class="n">generate_from_strs</span><span class="p">(</span><span class="n">src_strs</span><span class="p">,</span> <span class="n">generate_args</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">pred_strs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).
To remove this error, you can add a new pad token and then resize model embedding:
	tokenizer.pad_token = &#39;&lt;PAD&gt;&#39;
	model.resize_token_embeddings(len(tokenizer))
Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).
To remove this error, you can add a new pad token and then resize model embedding:
	tokenizer.pad_token = &#39;&lt;PAD&gt;&#39;
	model.resize_token_embeddings(len(tokenizer))
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39; encodegrowthgrowthgrowthgrowthgrowthgrowthgrowth&#39;,
 &#39; Economy Economy Economy Economy Economy Economy Economy Economy&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Test for GeneratedBert2GPT2</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">BertEncoder</span><span class="p">(</span><span class="s1">&#39;hfl/chinese-bert-wwm-ext&#39;</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">GPT2Decoder</span><span class="p">(</span>
    <span class="s1">&#39;distilgpt2&#39;</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">dec_tokenizer</span><span class="p">),</span>
    <span class="n">num_heads</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">drop_p</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">bert2gpt2</span> <span class="o">=</span> <span class="n">Bert2GPT2</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">)</span>
<span class="n">generated_bert2gpt2</span> <span class="o">=</span> <span class="n">GeneratedBert2GPT2</span><span class="p">(</span><span class="n">bert2gpt2</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="p">)</span>

<span class="n">generate_args</span> <span class="o">=</span> <span class="n">GenerateArgs</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">src_strs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;天氣不錯&#39;</span><span class="p">,</span> <span class="s1">&#39;你好&#39;</span><span class="p">]</span>
<span class="n">pred_strs</span> <span class="o">=</span> <span class="n">generated_bert2gpt2</span><span class="o">.</span><span class="n">generate_from_strs</span><span class="p">(</span><span class="n">src_strs</span><span class="p">,</span> <span class="n">generate_args</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">pred_strs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).
To remove this error, you can add a new pad token and then resize model embedding:
	tokenizer.pad_token = &#39;&lt;PAD&gt;&#39;
	model.resize_token_embeddings(len(tokenizer))
Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).
To remove this error, you can add a new pad token and then resize model embedding:
	tokenizer.pad_token = &#39;&lt;PAD&gt;&#39;
	model.resize_token_embeddings(len(tokenizer))
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39; boss boss boss boss boss boss boss boss&#39;,
 &#39; supervisors supervisors supervisors supervisors supervisors supervisors supervisors supervisors&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Test for GeneratedQRNN2QRNN</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">QRNNEncoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">enc_tokenizer</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">QRNNDecoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dec_tokenizer</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">qrnn2qrnn</span> <span class="o">=</span> <span class="n">QRNN2QRNN</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">generated_qrnn2qrnn</span> <span class="o">=</span> <span class="n">GeneratedQRNN2QRNN</span><span class="p">(</span><span class="n">qrnn2qrnn</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="p">)</span>

<span class="n">generate_args</span> <span class="o">=</span> <span class="n">GenerateArgs</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">src_strs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;天氣不錯&#39;</span><span class="p">,</span> <span class="s1">&#39;你好&#39;</span><span class="p">]</span>
<span class="n">pred_strs</span> <span class="o">=</span> <span class="n">generated_qrnn2qrnn</span><span class="o">.</span><span class="n">generate_from_strs</span><span class="p">(</span><span class="n">src_strs</span><span class="p">,</span> <span class="n">generate_args</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">pred_strs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).
To remove this error, you can add a new pad token and then resize model embedding:
	tokenizer.pad_token = &#39;&lt;PAD&gt;&#39;
	model.resize_token_embeddings(len(tokenizer))
Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).
To remove this error, you can add a new pad token and then resize model embedding:
	tokenizer.pad_token = &#39;&lt;PAD&gt;&#39;
	model.resize_token_embeddings(len(tokenizer))
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39; four Antar XTmillion Zstri david funding&#39;,
 &#39; Fame therapeutic Ruk climb Kee bacter TekUpload&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Test for GeneratedQRNN2AttnQRNN</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">QRNNEncoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">enc_tokenizer</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">CrossAttnQRNNDecoder</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dec_tokenizer</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">qrnn2attnqrnn</span> <span class="o">=</span> <span class="n">QRNN2AttnQRNN</span><span class="p">(</span><span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">generated_qrnn2attnqrnn</span> <span class="o">=</span> <span class="n">GeneratedQRNN2AttnQRNN</span><span class="p">(</span><span class="n">qrnn2attnqrnn</span><span class="p">,</span> <span class="n">enc_tokenizer</span><span class="p">,</span> <span class="n">dec_tokenizer</span><span class="p">)</span>

<span class="n">generate_args</span> <span class="o">=</span> <span class="n">GenerateArgs</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_beams</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">src_strs</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;天氣不錯&#39;</span><span class="p">,</span> <span class="s1">&#39;你好&#39;</span><span class="p">]</span>
<span class="n">pred_strs</span> <span class="o">=</span> <span class="n">generated_qrnn2attnqrnn</span><span class="o">.</span><span class="n">generate_from_strs</span><span class="p">(</span><span class="n">src_strs</span><span class="p">,</span> <span class="n">generate_args</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">pred_strs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).
To remove this error, you can add a new pad token and then resize model embedding:
	tokenizer.pad_token = &#39;&lt;PAD&gt;&#39;
	model.resize_token_embeddings(len(tokenizer))
Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).
To remove this error, you can add a new pad token and then resize model embedding:
	tokenizer.pad_token = &#39;&lt;PAD&gt;&#39;
	model.resize_token_embeddings(len(tokenizer))
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39; Hound Hound Hound Hound Hound Hound Hound Hound&#39;,
 &#39; deputy deputy deputy deputy deputy deputy deputy deputy&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}
</div>
 

