{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "from fastai2.basics import *\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from fastai2_utils.data.all import *\n",
    "from fastai_transformers_utils.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.tatoeba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Tatoeba\n",
    "> Chinese to English pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data_loc = './test_data/cmn.txt'\n",
    "tok_data_loc = './test_data/tok_cmn.csv'\n",
    "enc_tokenizer = AutoTokenizer.from_pretrained('hfl/chinese-bert-wwm-ext')\n",
    "dec_tokenizer = GPT2DecoderTokenizer.from_pretrained('distilgpt2')\n",
    "enc_seq_len = 50\n",
    "dec_seq_len = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _tokenize_data(ori_data_loc, enc_tokenizer, dec_tokenizer):\n",
    "    df = pd.read_csv(ori_data_loc, header=None, names=['English', 'Chinese', 'Contributor'], delimiter='\\t')\n",
    "    df.drop(['Contributor'], axis=1, inplace=True)\n",
    "    \n",
    "    tok_df = df.copy()\n",
    "    encoder_tok_list = L(parallel_gen(TransformersTokenizer, df.Chinese, tokenizer=enc_tokenizer)).sorted().itemgot(1)\n",
    "    tok_df.Chinese =  encoder_tok_list.map(lambda x: ' '.join(x)) # split tokens by ' '\n",
    "    decoder_tok_list = L(parallel_gen(TransformersTokenizer, df.English, tokenizer=dec_tokenizer)).sorted().itemgot(1)\n",
    "    tok_df.English =  decoder_tok_list.map(lambda x: ' '.join(x)) # split tokens by ' '\n",
    "    \n",
    "    is_valid = np.zeros(len(tok_df))\n",
    "    is_valid[:int(len(tok_df)*0.2)] = 1\n",
    "    np.random.RandomState(42).shuffle(is_valid)\n",
    "    is_valid = is_valid.astype(np.bool)\n",
    "    tok_df['is_valid'] = is_valid\n",
    "\n",
    "    return tok_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|bos|&gt; Hi . &lt;|endoftext|&gt;</td>\n",
       "      <td>嗨 。</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|bos|&gt; Hi . &lt;|endoftext|&gt;</td>\n",
       "      <td>你 好 。</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|bos|&gt; Run . &lt;|endoftext|&gt;</td>\n",
       "      <td>你 用 跑 的 。</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|bos|&gt; Wait ! &lt;|endoftext|&gt;</td>\n",
       "      <td>等 等 ！</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|bos|&gt; Hello ! &lt;|endoftext|&gt;</td>\n",
       "      <td>你 好 。</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21200</th>\n",
       "      <td>&lt;|bos|&gt; Last Ġyear Ġin Ġthe ĠPhilippines , Ġearthquakes Ġand Ġtidal Ġwaves Ġresulted Ġin Ġthe Ġdeaths Ġof Ġmore Ġthan Ġ6 , 000 Ġpeople . &lt;|endoftext|&gt;</td>\n",
       "      <td>去 年 在 菲 律 宾 ， 地 震 和 海 啸 造 成 了 超 过 6000 人 的 死 亡 。</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21201</th>\n",
       "      <td>&lt;|bos|&gt; My Ġmother Ġspeaks ĠFrench Ġbetter Ġthan Ġmy Ġfather Ġspeaks ĠEnglish , Ġso Ġthey Ġusually Ġspeak Ġto Ġeach Ġother Ġin ĠFrench . &lt;|endoftext|&gt;</td>\n",
       "      <td>我 母 亲 的 法 语 比 我 父 亲 的 英 语 要 好 ， 所 以 他 们 通 常 用 法 语 交 流 。</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21202</th>\n",
       "      <td>&lt;|bos|&gt; Tom Ġdidn 't Ġknow Ġhow Ġto Ġtranslate Ġthe Ġword Ġ\" computer \" Ġbecause Ġthe Ġpeople Ġhe Ġwas Ġtalking Ġto Ġhad Ġnever Ġseen Ġone . &lt;|endoftext|&gt;</td>\n",
       "      <td>汤 姆 不 知 如 何 翻 译 [UNK] 计 算 机 [UNK] 一 词 ， 因 为 同 他 谈 话 的 人 从 未 见 过 一 台 。</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21203</th>\n",
       "      <td>&lt;|bos|&gt; Even Ġnow , ĠI Ġoccasionally Ġthink ĠI 'd Ġlike Ġto Ġsee Ġyou . ĠNot Ġthe Ġyou Ġthat Ġyou Ġare Ġtoday , Ġbut Ġthe Ġyou ĠI Ġremember Ġfrom Ġthe Ġpast . &lt;|endoftext|&gt;</td>\n",
       "      <td>即 使 是 现 在 ， 我 偶 尔 还 是 想 见 到 你 。 不 是 今 天 的 你 ， 而 是 我 记 忆 中 曾 经 的 你 。</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21204</th>\n",
       "      <td>&lt;|bos|&gt; If Ġa Ġperson Ġhas Ġnot Ġhad Ġa Ġchance Ġto Ġacquire Ġhis Ġtarget Ġlanguage Ġby Ġthe Ġtime Ġhe 's Ġan Ġadult , Ġhe 's Ġunlikely Ġto Ġbe Ġable Ġto Ġreach Ġnative Ġspeaker Ġlevel Ġin Ġthat Ġlanguage . &lt;|endoftext|&gt;</td>\n",
       "      <td>如 果 一 個 人 在 成 人 前 沒 有 機 會 習 得 目 標 語 言 ， 他 對 該 語 言 的 認 識 達 到 母 語 者 程 度 的 機 會 是 相 當 小 的 。</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21205 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                            English  ... is_valid\n",
       "0                                                                                                                                                                                                        <|bos|> Hi . <|endoftext|>  ...    False\n",
       "1                                                                                                                                                                                                        <|bos|> Hi . <|endoftext|>  ...    False\n",
       "2                                                                                                                                                                                                       <|bos|> Run . <|endoftext|>  ...    False\n",
       "3                                                                                                                                                                                                      <|bos|> Wait ! <|endoftext|>  ...    False\n",
       "4                                                                                                                                                                                                     <|bos|> Hello ! <|endoftext|>  ...    False\n",
       "...                                                                                                                                                                                                                             ...  ...      ...\n",
       "21200                                                                        <|bos|> Last Ġyear Ġin Ġthe ĠPhilippines , Ġearthquakes Ġand Ġtidal Ġwaves Ġresulted Ġin Ġthe Ġdeaths Ġof Ġmore Ġthan Ġ6 , 000 Ġpeople . <|endoftext|>  ...    False\n",
       "21201                                                                        <|bos|> My Ġmother Ġspeaks ĠFrench Ġbetter Ġthan Ġmy Ġfather Ġspeaks ĠEnglish , Ġso Ġthey Ġusually Ġspeak Ġto Ġeach Ġother Ġin ĠFrench . <|endoftext|>  ...    False\n",
       "21202                                                                    <|bos|> Tom Ġdidn 't Ġknow Ġhow Ġto Ġtranslate Ġthe Ġword Ġ\" computer \" Ġbecause Ġthe Ġpeople Ġhe Ġwas Ġtalking Ġto Ġhad Ġnever Ġseen Ġone . <|endoftext|>  ...    False\n",
       "21203                                                  <|bos|> Even Ġnow , ĠI Ġoccasionally Ġthink ĠI 'd Ġlike Ġto Ġsee Ġyou . ĠNot Ġthe Ġyou Ġthat Ġyou Ġare Ġtoday , Ġbut Ġthe Ġyou ĠI Ġremember Ġfrom Ġthe Ġpast . <|endoftext|>  ...     True\n",
       "21204  <|bos|> If Ġa Ġperson Ġhas Ġnot Ġhad Ġa Ġchance Ġto Ġacquire Ġhis Ġtarget Ġlanguage Ġby Ġthe Ġtime Ġhe 's Ġan Ġadult , Ġhe 's Ġunlikely Ġto Ġbe Ġable Ġto Ġreach Ġnative Ġspeaker Ġlevel Ġin Ġthat Ġlanguage . <|endoftext|>  ...    False\n",
       "\n",
       "[21205 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip\n",
    "# tokenize data and save it to tok_data_loc\n",
    "tok_df = _tokenize_data(ori_data_loc, enc_tokenizer, dec_tokenizer)\n",
    "tok_df.to_csv(tok_data_loc, index=False)\n",
    "pd.read_csv(tok_data_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_tatoeba_dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_tatoeba_dss(tok_data_loc, enc_tokenizer, dec_tokenizer, enc_seq_len, dec_seq_len, pct=1.0):\n",
    "    tok_df = pd.read_csv(tok_data_loc)\n",
    "    \n",
    "    splits = ColSplitter()(tok_df)\n",
    "    splits = pct_splits(splits, pct=pct)\n",
    "    \n",
    "    encoder_input_tfm = [attrgetter('Chinese'), lambda x: x.split(' '), TransformersNumericalize(enc_tokenizer), Pad2Max(enc_seq_len, enc_tokenizer.pad_token_id)]\n",
    "    decoder_input_tfm = [attrgetter('English'), lambda x: x.split(' '), TransformersNumericalize(dec_tokenizer), Pad2Max(dec_seq_len+1, dec_tokenizer.pad_token_id), lambda x: x[:-1]]\n",
    "    decoder_output_tfm = [attrgetter('English'), lambda x: x.split(' '), TransformersNumericalize(dec_tokenizer), Pad2Max(dec_seq_len+1, dec_tokenizer.pad_token_id), lambda x: x[1:]]\n",
    "    ds_tfms = [\n",
    "        encoder_input_tfm,\n",
    "        decoder_input_tfm,\n",
    "        decoder_output_tfm,\n",
    "    ]\n",
    "    \n",
    "    dss = Datasets(tok_df, tfms=ds_tfms, splits=splits, n_inp=2)\n",
    "    return dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dss = get_tatoeba_dss(tok_data_loc, enc_tokenizer, dec_tokenizer, enc_seq_len, dec_seq_len, pct=0.5)\n",
    "dss = get_tatoeba_dss(tok_data_loc, enc_tokenizer, dec_tokenizer, enc_seq_len, dec_seq_len)\n",
    "test_eq(len(small_dss.train), len(dss.train)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorText([ 101,  800, 6651,  749,  511,  102,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0]),\n",
       "  TensorText([50257,  1544,  4966,    13, 50256, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258]),\n",
       "  TensorText([ 1544,  4966,    13, 50256, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258])),\n",
       " ('[CLS] 他 跑 了 。 [SEP]',\n",
       "  '<|bos|> He ran.<|endoftext|>',\n",
       "  'He ran.<|endoftext|>'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dss.train[10], dss.decode(dss.train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 50]) torch.int64 cuda:0 <class 'fastai2.text.data.TensorText'>\n",
      "torch.Size([2, 40]) torch.int64 cuda:0 <class 'fastai2.text.data.TensorText'>\n",
      "torch.Size([2, 40]) torch.int64 cuda:0 <class 'fastai2.text.data.TensorText'>\n"
     ]
    }
   ],
   "source": [
    "dls = dss.dataloaders(bs=2)\n",
    "for x in dls.train:\n",
    "    print(x[0].shape, x[0].dtype, x[0].device, type(x[0]))\n",
    "    print(x[1].shape, x[1].dtype, x[1].device, type(x[1]))\n",
    "    print(x[2].shape, x[2].dtype, x[2].device, type(x[2]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 02_data.tatoeba.ipynb.\n",
      "Converted 03a_models.patch.ipynb.\n",
      "Converted 03c_models.bert2gpt2.ipynb.\n",
      "Converted 03c_models.gru2gru.ipynb.\n",
      "Converted 03c_models.tran2tran.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
