{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai2.basics import *\n",
    "from transformers import AutoTokenizer\n",
    "from fastai_transformers_utils.all import *\n",
    "\n",
    "from nmt_small.models.patch import *\n",
    "from nmt_small.models.gru2gru import GRUEncoder, GRUDecoder, GRU2GRU, GeneratedGRU2GRU\n",
    "from nmt_small.data.tatoeba import get_datasets\n",
    "from nmt_small.metrics import compute_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_data_loc = './data/tatoeba/tok_cmn.csv'\n",
    "enc_model_name = 'hfl/chinese-bert-wwm-ext'\n",
    "dec_model_name = 'distilgpt2'\n",
    "enc_seq_len = 50\n",
    "dec_seq_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_tokenizer = AutoTokenizer.from_pretrained(enc_model_name)\n",
    "dec_tokenizer = GPT2DecoderTokenizer.from_pretrained(dec_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3392, 16964)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dss = get_datasets(tok_data_loc, enc_tokenizer, dec_tokenizer, enc_seq_len, dec_seq_len, pct=0.2)\n",
    "dss = get_datasets(tok_data_loc, enc_tokenizer, dec_tokenizer, enc_seq_len, dec_seq_len)\n",
    "len(small_dss.train), len(dss.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorText([ 101,  800, 6651,  749,  511,  102,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0]),\n",
       "  TensorText([50257,  1544,  4966,    13, 50256, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258]),\n",
       "  TensorText([ 1544,  4966,    13, 50256, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258])),\n",
       " ('[CLS] 他 跑 了 。 [SEP]',\n",
       "  '<|bos|> He ran.<|endoftext|>',\n",
       "  'He ran.<|endoftext|>'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dss.train[10], dss.decode(dss.train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls = dss.dataloaders(bs=2)\n",
    "# for x in dls.train:\n",
    "#     print(x[0].shape, x[0].dtype, x[0].device, type(x[0]))\n",
    "#     print(x[1].shape, x[1].dtype, x[0].device, type(x[1]))\n",
    "#     print(x[2].shape, x[2].dtype, x[0].device, type(x[2]))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_vocab_size = len(enc_tokenizer)\n",
    "enc_pad_id = enc_tokenizer.pad_token_id\n",
    "\n",
    "dec_vocab_size = len(dec_tokenizer)\n",
    "dec_pad_id = dec_tokenizer.pad_token_id\n",
    "\n",
    "embeded_size = 256\n",
    "num_encoder_layers = 2\n",
    "num_decoder_layers = 2\n",
    "drop_p = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GRUEncoder(enc_vocab_size, embeded_size, enc_pad_id, num_encoder_layers, drop_p)\n",
    "decoder = GRUDecoder(dec_vocab_size, embeded_size, dec_pad_id, num_decoder_layers, drop_p)\n",
    "gru2gru = GRU2GRU(encoder, decoder, num_encoder_layers, num_decoder_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = small_dss.dataloaders(bs=128)\n",
    "# dls = dss.dataloaders(bs=128)\n",
    "learn = Learner(dls, \n",
    "                gru2gru, \n",
    "                loss_func=CrossEntropyLossFlat(ignore_index=dec_pad_id), \n",
    "                opt_func=Adam,\n",
    "                metrics=[accuracy, Perplexity()],\n",
    "               ).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.083679</td>\n",
       "      <td>4.304209</td>\n",
       "      <td>0.078808</td>\n",
       "      <td>74.010666</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.637716</td>\n",
       "      <td>3.218691</td>\n",
       "      <td>0.098456</td>\n",
       "      <td>24.995388</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.612543</td>\n",
       "      <td>2.774764</td>\n",
       "      <td>0.111159</td>\n",
       "      <td>16.034840</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.717289</td>\n",
       "      <td>2.697780</td>\n",
       "      <td>0.113753</td>\n",
       "      <td>14.846741</td>\n",
       "      <td>00:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_args = GenerateArgs(   \n",
    "    max_length=20,\n",
    "#     do_sample=True,\n",
    "    num_beams=3,\n",
    "    temperature=1.0,\n",
    "    repetition_penalty=1,\n",
    "    length_penalty=1.0,\n",
    ")\n",
    "generated_gru2gru = GeneratedGRU2GRU(gru2gru, enc_tokenizer, dec_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='67' class='' max='67', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [67/67 00:58<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.12515677326505098"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bleu(generated_gru2gru, generate_args, dec_tokenizer, dls.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_strs = ['你确定？', \n",
    "            '找到汤姆。', \n",
    "            '帮帮我们吧！',\n",
    "            '坚持。']\n",
    "tgt_strs = [\"Really?\",\n",
    "           \"Get Tom.\",\n",
    "           \"Help us.\",\n",
    "           \"Hold on.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Are you sure you want to do that?',\n",
       " ' Tom is Tom to find Tom.',\n",
       " \"Let's go to us.\",\n",
       " \"It's a bit of children.\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = generated_gru2gru.generate_from_strs(src_strs, generate_args, device='cuda:0')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_strs = ['我很高興再次見到你。', \n",
    "            '我有點累。', \n",
    "            '我不記得寄過信了。',\n",
    "            '它是我兄弟的。']\n",
    "tgt_strs = [\"I'm very glad to see you again.\",\n",
    "           \"I'm a little tired.\",\n",
    "           \"I don't remember mailing the letter.\",\n",
    "           \"It's my brother's.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm glad to see you again.\",\n",
       " 'I am tired of being tired.',\n",
       " \"I don't remember the letter better than I remember.\",\n",
       " \"It's my brother is my brother.\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = generated_gru2gru.generate_from_strs(src_strs, generate_args, device='cuda:0')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
