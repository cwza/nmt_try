{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai2.basics import *\n",
    "from transformers import AutoTokenizer\n",
    "from fastai_transformers_utils.all import *\n",
    "\n",
    "from nmt_small.models.patch import *\n",
    "from nmt_small.models.tran2tran import TranEncoder, TranDecoder, Tran2Tran, GeneratedTran2Tran\n",
    "from nmt_small.data.tatoeba import get_datasets\n",
    "from nmt_small.metrics import compute_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_data_loc = './data/tatoeba/tok_cmn.csv'\n",
    "enc_model_name = 'hfl/chinese-bert-wwm-ext'\n",
    "dec_model_name = 'distilgpt2'\n",
    "enc_seq_len = 50\n",
    "dec_seq_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_tokenizer = AutoTokenizer.from_pretrained(enc_model_name)\n",
    "dec_tokenizer = GPT2DecoderTokenizer.from_pretrained(dec_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3392, 16964)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dss = get_datasets(tok_data_loc, enc_tokenizer, dec_tokenizer, enc_seq_len, dec_seq_len, pct=0.2)\n",
    "dss = get_datasets(tok_data_loc, enc_tokenizer, dec_tokenizer, enc_seq_len, dec_seq_len)\n",
    "len(small_dss.train), len(dss.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorText([ 101,  800, 6651,  749,  511,  102,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0]),\n",
       "  TensorText([50257,  1544,  4966,    13, 50256, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258]),\n",
       "  TensorText([ 1544,  4966,    13, 50256, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n",
       "          50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258])),\n",
       " ('[CLS] 他 跑 了 。 [SEP]',\n",
       "  '<|bos|> He ran.<|endoftext|>',\n",
       "  'He ran.<|endoftext|>'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dss.train[10], dss.decode(dss.train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls = dss.dataloaders(bs=2)\n",
    "# for x in dls.train:\n",
    "#     print(x[0].shape, x[0].dtype, x[0].device, type(x[0]))\n",
    "#     print(x[1].shape, x[1].dtype, x[0].device, type(x[1]))\n",
    "#     print(x[2].shape, x[2].dtype, x[0].device, type(x[2]))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_max_pos_id = enc_seq_len+10\n",
    "enc_vocab_size = len(enc_tokenizer)\n",
    "enc_pad_id = enc_tokenizer.pad_token_id\n",
    "\n",
    "dec_max_pos_id = dec_seq_len+10\n",
    "dec_vocab_size = len(dec_tokenizer)\n",
    "dec_pad_id = dec_tokenizer.pad_token_id\n",
    "\n",
    "embeded_size = 256\n",
    "num_head = 2\n",
    "num_encoder_layers = 2\n",
    "num_decoder_layers = 2\n",
    "dim_feedforward = 512\n",
    "drop_p = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TranEncoder(enc_vocab_size, embeded_size, enc_max_pos_id, enc_pad_id)\n",
    "decoder = TranDecoder(dec_vocab_size, embeded_size, dec_max_pos_id, dec_pad_id)\n",
    "tran2tran = Tran2Tran(encoder, decoder, enc_pad_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = small_dss.dataloaders(bs=64)\n",
    "# dls = dss.dataloaders(bs=64)\n",
    "learn = Learner(dls, \n",
    "                tran2tran, \n",
    "                loss_func=CrossEntropyLossFlat(ignore_index=dec_pad_id), \n",
    "                opt_func=Adam,\n",
    "                metrics=[accuracy, Perplexity()],\n",
    "               ).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.960009</td>\n",
       "      <td>4.365407</td>\n",
       "      <td>0.077918</td>\n",
       "      <td>78.681381</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.909053</td>\n",
       "      <td>3.646549</td>\n",
       "      <td>0.091069</td>\n",
       "      <td>38.342098</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.410864</td>\n",
       "      <td>3.293607</td>\n",
       "      <td>0.099853</td>\n",
       "      <td>26.939867</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.098508</td>\n",
       "      <td>3.188998</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>24.264109</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, 5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_args = GenerateArgs(   \n",
    "    max_length=20,\n",
    "#     do_sample=True,\n",
    "    num_beams=3,\n",
    "    temperature=1.0,\n",
    "    repetition_penalty=1,\n",
    "    length_penalty=1.0,\n",
    ")\n",
    "generated_tran2tran = GeneratedTran2Tran(tran2tran, enc_tokenizer, dec_tokenizer)\n",
    "# dls = dss.dataloaders(bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14' class='' max='14', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14/14 00:21<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.01570638370580385"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bleu(generated_tran2tran, generate_args, dec_tokenizer, dls.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_strs = ['你确定？', \n",
    "            '找到汤姆。', \n",
    "            '帮帮我们吧！',\n",
    "            '坚持。']\n",
    "tgt_strs = [\"Really?\",\n",
    "           \"Get Tom.\",\n",
    "           \"Help us.\",\n",
    "           \"Hold on.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Are you busy?',\n",
       " 'Tom is going to see.',\n",
       " \"Let's play the door.\",\n",
       " \"There's a car.\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = generated_tran2tran.generate_from_strs(src_strs, generate_args, device='cuda:0')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_strs = ['我很高興再次見到你。', \n",
    "            '我有點累。', \n",
    "            '我不記得寄過信了。',\n",
    "            '它是我兄弟的。']\n",
    "tgt_strs = [\"I'm very glad to see you again.\",\n",
    "           \"I'm a little tired.\",\n",
    "           \"I don't remember mailing the letter.\",\n",
    "           \"It's my brother's.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm glad to see you.\",\n",
       " \"I'm afraid of it.\",\n",
       " \"I don't think it's too much.\",\n",
       " \"It's my sister.\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = generated_tran2tran.generate_from_strs(src_strs, generate_args, device='cuda:0')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
