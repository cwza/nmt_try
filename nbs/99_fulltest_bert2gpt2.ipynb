{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna\n",
    "from fastai2.basics import *\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from fastai2_utils.pytorch.model import *\n",
    "from fastai_transformers_utils.all import *\n",
    "\n",
    "from nmt_small.models.patch import *\n",
    "from nmt_small.models.bert2gpt2 import *\n",
    "from nmt_small.data.tatoeba import *\n",
    "from nmt_small.metrics import compute_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_data_loc = './test_data/tok_cmn.csv'\n",
    "enc_model_name = 'hfl/chinese-bert-wwm-ext'\n",
    "dec_model_name = 'distilgpt2'\n",
    "enc_seq_len = 50\n",
    "dec_seq_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_tokenizer = AutoTokenizer.from_pretrained(enc_model_name)\n",
    "dec_tokenizer = GPT2DecoderTokenizer.from_pretrained(dec_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Test of Bert2GPT2\n",
    "\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3392, 16964)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dss = get_tatoeba_dss(tok_data_loc, enc_tokenizer, dec_tokenizer, enc_seq_len, dec_seq_len, pct=0.2)\n",
    "dss = get_tatoeba_dss(tok_data_loc, enc_tokenizer, dec_tokenizer, enc_seq_len, dec_seq_len)\n",
    "len(small_dss.train), len(dss.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dss.train[10], dss.decode(dss.train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls = dss.dataloaders(bs=2)\n",
    "# for x in dls.train:\n",
    "#     print(x[0].shape, x[0].dtype, x[0].device, type(x[0]))\n",
    "#     print(x[1].shape, x[1].dtype, x[0].device, type(x[1]))\n",
    "#     print(x[2].shape, x[2].dtype, x[0].device, type(x[2]))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(device):\n",
    "    encoder = BertEncoder(enc_model_name)\n",
    "    decoder = GPT2Decoder(\n",
    "        dec_model_name, dec_tokenizer.pad_token_id,\n",
    "        vocab_size=len(dec_tokenizer),\n",
    "        num_heads=2, drop_p=0, num_layers=2,\n",
    "    )\n",
    "    model = Bert2GPT2(encoder, decoder, enc_tokenizer.pad_token_id)\n",
    "    model.to(device)\n",
    "    return model\n",
    "model = get_model('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = small_dss.dataloaders(bs=16)\n",
    "# dls = dss.dataloaders(bs=64)\n",
    "learn = Learner(dls, \n",
    "                model, \n",
    "                loss_func=CrossEntropyLossFlat(ignore_index=dec_tokenizer.pad_token_id), \n",
    "                opt_func=Adam,\n",
    "                metrics=[accuracy, Perplexity()],\n",
    "               ).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.631876</td>\n",
       "      <td>5.479174</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>239.648590</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# freeze_to(decoder.layer_groups, -3) # only train cross attention and later layer\n",
    "learn.fit_one_cycle(1, 5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_args = GenerateArgs(   \n",
    "#     max_length=20,\n",
    "# #     do_sample=True,\n",
    "#     num_beams=3,\n",
    "#     temperature=1.0,\n",
    "#     repetition_penalty=1,\n",
    "#     length_penalty=1.0,\n",
    "# )\n",
    "# generated_bert2gpt2 = GeneratedBert2GPT2(bert2gpt2, enc_tokenizer, dec_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_bleu(generated_bert2gpt2, generate_args, dec_tokenizer, dls.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_strs = ['你确定？', \n",
    "#             '找到汤姆。', \n",
    "#             '帮帮我们吧！',\n",
    "#             '坚持。']\n",
    "# tgt_strs = [\"Really?\",\n",
    "#            \"Get Tom.\",\n",
    "#            \"Help us.\",\n",
    "#            \"Hold on.\"]\n",
    "# result = generated_bert2gpt2.generate_from_strs(src_strs, generate_args, device='cuda:0')\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_strs = ['我很高興再次見到你。', \n",
    "#             '我有點累。', \n",
    "#             '我不記得寄過信了。',\n",
    "#             '它是我兄弟的。']\n",
    "# tgt_strs = [\"I'm very glad to see you again.\",\n",
    "#            \"I'm a little tired.\",\n",
    "#            \"I don't remember mailing the letter.\",\n",
    "#            \"It's my brother's.\"]\n",
    "# result = generated_bert2gpt2.generate_from_strs(src_strs, generate_args, device='cuda:0')\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Objective():\n",
    "#     def __init__(self):\n",
    "#         self.dls = dss.dataloaders(bs=64)\n",
    "#         self.model = get_model(default_device())\n",
    "#         torch.save(self.model.state_dict(), './models/bert2gpt2_ori.pt')\n",
    "\n",
    "#     def objective(self, trial):\n",
    "#         lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
    "#         self.model.load_state_dict(torch.load('./models/bert2gpt2_ori.pt'))\n",
    "#         learn = Learner(self.dls, \n",
    "#                     self.model, \n",
    "#                     loss_func=CrossEntropyLossFlat(ignore_index=dec_tokenizer.pad_token_id), \n",
    "#                     opt_func=Adam,\n",
    "#                     metrics=[accuracy, Perplexity()],\n",
    "#                    ).to_fp16()\n",
    "#         print(f'Current trial: {trial.number} lr: {lr}')\n",
    "#         learn.fit_one_cycle(1, lr)\n",
    "#         return learn.recorder.log[4]\n",
    "    \n",
    "#     def clear(self):\n",
    "#         self.model.to('cpu')\n",
    "#         self.dls.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study()\n",
    "# objective = Objective()\n",
    "# study.optimize(objective.objective, n_trials=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
