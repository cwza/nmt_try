{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "from transformers import AutoTokenizer\n",
    "from fastai2.basics import *\n",
    "\n",
    "from fastai_transformers_utils.generated_lm import GenerateArgs\n",
    "from fastai_transformers_utils.tokenizers import GPT2DecoderTokenizer\n",
    "\n",
    "from nmt_try.models.gru2gru import GeneratedGRU2GRU, GRUEncoder, GRUDecoder, GRU2GRU\n",
    "from nmt_try.models.tran2tran import GeneratedTran2Tran, TranEncoder, TranDecoder, Tran2Tran\n",
    "from nmt_try.models.bert2gpt2 import BertEncoder, GPT2Decoder, Bert2GPT2, GeneratedBert2GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Patch\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_tokenizer = AutoTokenizer.from_pretrained('hfl/chinese-bert-wwm-ext')\n",
    "dec_tokenizer = GPT2DecoderTokenizer.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneratedSeq2Seq.generate_from_strs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "@torch.no_grad()\n",
    "def generate_from_strs(self: [GeneratedTran2Tran, GeneratedGRU2GRU, GeneratedBert2GPT2], src_strs, generate_args: GenerateArgs, device):\n",
    "    ''' self.seq2seq.eval, self.enc_tokenizer.encode, self.dec_tokenizer.decode, self.generate_from_ids '''\n",
    "    self.seq2seq.eval()\n",
    "    \n",
    "    pred_strs = []\n",
    "    for src_str in src_strs:\n",
    "        src_id = self.enc_tokenizer.encode(src_str)\n",
    "        src_ids = torch.tensor([src_id], device=device)\n",
    "        pred_ids = self.generate_from_ids(src_ids, generate_args)\n",
    "        pred_str = self.dec_tokenizer.decode(pred_ids[0], skip_special_tokens=True)\n",
    "        pred_strs.append(pred_str)\n",
    "    return pred_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' smiles unemploymentophone corporatepai first obserpre',\n",
       " ' smiles unemployment orally Lifetime depression sheltered Rhod Jedi']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for GeneratedGRU2GRU\n",
    "encoder = GRUEncoder(len(enc_tokenizer), 256, enc_tokenizer.pad_token_id, 1)\n",
    "decoder = GRUDecoder(len(dec_tokenizer), 256, dec_tokenizer.pad_token_id, 1)\n",
    "gru2gru = GRU2GRU(encoder, decoder, 1, 1)\n",
    "generated_gru2gru = GeneratedGRU2GRU(gru2gru, enc_tokenizer, dec_tokenizer)\n",
    "\n",
    "generate_args = GenerateArgs(max_length=10, num_beams=2)\n",
    "src_strs = ['天氣不錯', '你好']\n",
    "pred_strs = generated_gru2gru.generate_from_strs(src_strs, generate_args, device='cpu')\n",
    "pred_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biansbians outsbians outsbians outs authored',\n",
       " 'token shatter shatter shatter shatter shatter shatter shatter']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for GeneratedTran2Tran\n",
    "encoder = TranEncoder(len(enc_tokenizer), 256, 100, enc_tokenizer.pad_token_id)\n",
    "decoder = TranDecoder(len(dec_tokenizer), 256, 100, dec_tokenizer.pad_token_id)\n",
    "tran2tran = Tran2Tran(encoder, decoder, enc_tokenizer.pad_token_id)\n",
    "generated_tran2tran = GeneratedTran2Tran(tran2tran, enc_tokenizer, dec_tokenizer)\n",
    "\n",
    "generate_args = GenerateArgs(max_length=10, num_beams=2)\n",
    "src_strs = ['天氣不錯', '你好']\n",
    "pred_strs = generated_tran2tran.generate_from_strs(src_strs, generate_args, device='cpu')\n",
    "pred_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for GeneratedBert2GPT2\n",
    "encoder = BertEncoder('hfl/chinese-bert-wwm-ext')\n",
    "decoder = GPT2Decoder(\n",
    "    'distilgpt2', dec_tokenizer.pad_token_id,\n",
    "    vocab_size=len(dec_tokenizer),\n",
    "    num_heads=2, drop_p=0, num_layers=2,\n",
    ")\n",
    "bert2gpt2 = Bert2GPT2(encoder, decoder, enc_tokenizer.pad_token_id)\n",
    "generated_bert2gpt2 = GeneratedBert2GPT2(bert2gpt2, enc_tokenizer, dec_tokenizer)\n",
    "\n",
    "generate_args = GenerateArgs(max_length=10, num_beams=2)\n",
    "src_strs = ['天氣不錯', '你好']\n",
    "pred_strs = generated_bert2gpt2.generate_from_strs(src_strs, generate_args, device='cpu')\n",
    "pred_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 02_data.tatoeba.ipynb.\n",
      "Converted 03a_models.patch.ipynb.\n",
      "Converted 03c_models.bert2gpt2.ipynb.\n",
      "Converted 03c_models.gru2gru.ipynb.\n",
      "Converted 03c_models.tran2tran.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
