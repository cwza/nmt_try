{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from transformers import AutoTokenizer\n",
    "from fastai2.basics import *\n",
    "\n",
    "from fastai_transformers_utils.generated_lm import GenerateArgs\n",
    "from fastai_transformers_utils.tokenizers import GPT2DecoderTokenizer\n",
    "\n",
    "from nmt_try.models.gru2gru import GeneratedGRU2GRU, GRUEncoder, GRUDecoder, GRU2GRU\n",
    "from nmt_try.models.tran2tran import GeneratedTran2Tran, TranEncoder, TranDecoder, Tran2Tran\n",
    "from nmt_try.models.bert2gpt2 import BertEncoder, GPT2Decoder, Bert2GPT2, GeneratedBert2GPT2\n",
    "from nmt_try.models.qrnn2qrnn import GeneratedQRNN2QRNN, QRNNEncoder, QRNNDecoder, QRNN2QRNN, GeneratedQRNN2AttnQRNN, CrossAttnQRNNDecoder, QRNN2AttnQRNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Patch\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_tokenizer = AutoTokenizer.from_pretrained('hfl/chinese-bert-wwm-ext')\n",
    "dec_tokenizer = GPT2DecoderTokenizer.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneratedSeq2Seq.generate_from_strs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "@torch.no_grad()\n",
    "def generate_from_strs(self: [GeneratedTran2Tran, GeneratedGRU2GRU, GeneratedBert2GPT2, GeneratedQRNN2QRNN, GeneratedQRNN2AttnQRNN], \n",
    "                       src_strs, generate_args: GenerateArgs, device):\n",
    "    ''' self.seq2seq.eval, self.enc_tokenizer.encode, self.dec_tokenizer.decode, self.generate_from_ids '''\n",
    "    self.seq2seq.eval()\n",
    "    \n",
    "    pred_strs = []\n",
    "    for src_str in src_strs:\n",
    "        src_id = self.enc_tokenizer.encode(src_str)\n",
    "        src_ids = torch.tensor([src_id], device=device)\n",
    "        pred_ids = self.generate_from_ids(src_ids, generate_args)\n",
    "        pred_str = self.dec_tokenizer.decode(list(pred_ids[0]), skip_special_tokens=True)\n",
    "        pred_strs.append(pred_str)\n",
    "    return pred_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).\n",
      "To remove this error, you can add a new pad token and then resize model embedding:\n",
      "\ttokenizer.pad_token = '<PAD>'\n",
      "\tmodel.resize_token_embeddings(len(tokenizer))\n",
      "Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).\n",
      "To remove this error, you can add a new pad token and then resize model embedding:\n",
      "\ttokenizer.pad_token = '<PAD>'\n",
      "\tmodel.resize_token_embeddings(len(tokenizer))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bo Stronghold Jian LW morality Tubico Welch',\n",
       " ' pondevaluate Retro HR Assass Productionsawa gate']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for GeneratedGRU2GRU\n",
    "encoder = GRUEncoder(len(enc_tokenizer), 256, enc_tokenizer.pad_token_id, 1)\n",
    "decoder = GRUDecoder(len(dec_tokenizer), 256, dec_tokenizer.pad_token_id, 1)\n",
    "gru2gru = GRU2GRU(encoder, decoder, 1, 1)\n",
    "generated_gru2gru = GeneratedGRU2GRU(gru2gru, enc_tokenizer, dec_tokenizer)\n",
    "\n",
    "generate_args = GenerateArgs(max_length=10, num_beams=2)\n",
    "src_strs = ['天氣不錯', '你好']\n",
    "pred_strs = generated_gru2gru.generate_from_strs(src_strs, generate_args, device='cpu')\n",
    "pred_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).\n",
      "To remove this error, you can add a new pad token and then resize model embedding:\n",
      "\ttokenizer.pad_token = '<PAD>'\n",
      "\tmodel.resize_token_embeddings(len(tokenizer))\n",
      "Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).\n",
      "To remove this error, you can add a new pad token and then resize model embedding:\n",
      "\ttokenizer.pad_token = '<PAD>'\n",
      "\tmodel.resize_token_embeddings(len(tokenizer))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' encodegrowthgrowthgrowthgrowthgrowthgrowthgrowth',\n",
       " ' Economy Economy Economy Economy Economy Economy Economy Economy']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for GeneratedTran2Tran\n",
    "encoder = TranEncoder(len(enc_tokenizer), 256, 100, enc_tokenizer.pad_token_id)\n",
    "decoder = TranDecoder(len(dec_tokenizer), 256, 100, dec_tokenizer.pad_token_id)\n",
    "tran2tran = Tran2Tran(encoder, decoder, enc_tokenizer.pad_token_id)\n",
    "generated_tran2tran = GeneratedTran2Tran(tran2tran, enc_tokenizer, dec_tokenizer)\n",
    "\n",
    "generate_args = GenerateArgs(max_length=10, num_beams=2)\n",
    "src_strs = ['天氣不錯', '你好']\n",
    "pred_strs = generated_tran2tran.generate_from_strs(src_strs, generate_args, device='cpu')\n",
    "pred_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).\n",
      "To remove this error, you can add a new pad token and then resize model embedding:\n",
      "\ttokenizer.pad_token = '<PAD>'\n",
      "\tmodel.resize_token_embeddings(len(tokenizer))\n",
      "Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).\n",
      "To remove this error, you can add a new pad token and then resize model embedding:\n",
      "\ttokenizer.pad_token = '<PAD>'\n",
      "\tmodel.resize_token_embeddings(len(tokenizer))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' boss boss boss boss boss boss boss boss',\n",
       " ' supervisors supervisors supervisors supervisors supervisors supervisors supervisors supervisors']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for GeneratedBert2GPT2\n",
    "encoder = BertEncoder('hfl/chinese-bert-wwm-ext')\n",
    "decoder = GPT2Decoder(\n",
    "    'distilgpt2', dec_tokenizer.pad_token_id,\n",
    "    vocab_size=len(dec_tokenizer),\n",
    "    num_heads=2, drop_p=0, num_layers=2,\n",
    ")\n",
    "bert2gpt2 = Bert2GPT2(encoder, decoder, enc_tokenizer.pad_token_id)\n",
    "generated_bert2gpt2 = GeneratedBert2GPT2(bert2gpt2, enc_tokenizer, dec_tokenizer)\n",
    "\n",
    "generate_args = GenerateArgs(max_length=10, num_beams=2)\n",
    "src_strs = ['天氣不錯', '你好']\n",
    "pred_strs = generated_bert2gpt2.generate_from_strs(src_strs, generate_args, device='cpu')\n",
    "pred_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).\n",
      "To remove this error, you can add a new pad token and then resize model embedding:\n",
      "\ttokenizer.pad_token = '<PAD>'\n",
      "\tmodel.resize_token_embeddings(len(tokenizer))\n",
      "Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).\n",
      "To remove this error, you can add a new pad token and then resize model embedding:\n",
      "\ttokenizer.pad_token = '<PAD>'\n",
      "\tmodel.resize_token_embeddings(len(tokenizer))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' four Antar XTmillion Zstri david funding',\n",
       " ' Fame therapeutic Ruk climb Kee bacter TekUpload']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for GeneratedQRNN2QRNN\n",
    "encoder = QRNNEncoder(len(enc_tokenizer), 256, enc_tokenizer.pad_token_id, 1)\n",
    "decoder = QRNNDecoder(len(dec_tokenizer), 256, dec_tokenizer.pad_token_id, 1)\n",
    "qrnn2qrnn = QRNN2QRNN(encoder, decoder, 1, 1)\n",
    "generated_qrnn2qrnn = GeneratedQRNN2QRNN(qrnn2qrnn, enc_tokenizer, dec_tokenizer)\n",
    "\n",
    "generate_args = GenerateArgs(max_length=10, num_beams=2)\n",
    "src_strs = ['天氣不錯', '你好']\n",
    "pred_strs = generated_qrnn2qrnn.generate_from_strs(src_strs, generate_args, device='cpu')\n",
    "pred_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).\n",
      "To remove this error, you can add a new pad token and then resize model embedding:\n",
      "\ttokenizer.pad_token = '<PAD>'\n",
      "\tmodel.resize_token_embeddings(len(tokenizer))\n",
      "Disabled padding because no padding token set (pad_token: [PAD], pad_token_id: 0).\n",
      "To remove this error, you can add a new pad token and then resize model embedding:\n",
      "\ttokenizer.pad_token = '<PAD>'\n",
      "\tmodel.resize_token_embeddings(len(tokenizer))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Hound Hound Hound Hound Hound Hound Hound Hound',\n",
       " ' deputy deputy deputy deputy deputy deputy deputy deputy']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for GeneratedQRNN2AttnQRNN\n",
    "encoder = QRNNEncoder(len(enc_tokenizer), 256, enc_tokenizer.pad_token_id, 1)\n",
    "decoder = CrossAttnQRNNDecoder(len(dec_tokenizer), 256, dec_tokenizer.pad_token_id, 1)\n",
    "qrnn2attnqrnn = QRNN2AttnQRNN(encoder, decoder, 1, 1, 256, 1)\n",
    "generated_qrnn2attnqrnn = GeneratedQRNN2AttnQRNN(qrnn2attnqrnn, enc_tokenizer, dec_tokenizer)\n",
    "\n",
    "generate_args = GenerateArgs(max_length=10, num_beams=2)\n",
    "src_strs = ['天氣不錯', '你好']\n",
    "pred_strs = generated_qrnn2attnqrnn.generate_from_strs(src_strs, generate_args, device='cpu')\n",
    "pred_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 02_data.news_commentary.ipynb.\n",
      "Converted 02_data.tatoeba.ipynb.\n",
      "Converted 03a_models.patch.ipynb.\n",
      "Converted 03c_models.bert2gpt2.ipynb.\n",
      "Converted 03c_models.gru2gru.ipynb.\n",
      "Converted 03c_models.qrnn2qrnn.ipynb.\n",
      "Converted 03c_models.tran2tran.ipynb.\n",
      "Converted 04_metrics.ipynb.\n",
      "Converted 90_fulltest_bert2gpt2.ipynb.\n",
      "Converted 90_fulltest_gru2gru.ipynb.\n",
      "Converted 90_fulltest_qrnn2attnqrnn.ipynb.\n",
      "Converted 90_fulltest_qrnn2qrnn.ipynb.\n",
      "Converted 90_fulltest_tran2tran.ipynb.\n",
      "Converted 95_nc_gru2gru.ipynb.\n",
      "Converted 95_nc_qrnn2qrnn.ipynb.\n",
      "Converted 95_nc_tran2tran.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
